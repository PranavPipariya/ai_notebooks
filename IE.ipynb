{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KnP4f-rZO-fV"
      },
      "outputs": [],
      "source": [
        "search_query = \"dogs\"\n",
        "search_url = f\"https://www.google.com/search?hl=en&tbm=isch&q={search_query}\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from bs4 import BeautifulSoup\n"
      ],
      "metadata": {
        "id": "cWRqHX2u-E1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = requests.get(search_url)\n"
      ],
      "metadata": {
        "id": "zl6ZVM5xPOBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "soup = BeautifulSoup(response.text, 'html.parser')\n"
      ],
      "metadata": {
        "id": "3WcqQrcTPSgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images = []\n",
        "for img in soup.find_all(\"img\"):\n",
        "    image_url = img.get(\"src\")  # Get the source of the image\n",
        "    if image_url and image_url.startswith(\"http\"):\n",
        "        images.append(image_url)\n"
      ],
      "metadata": {
        "id": "kO2sgBqwPVnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the URLs\n",
        "for image_url in images:\n",
        "    print(image_url)\n",
        "\n",
        "# Or, save to a file\n",
        "with open('dog_images_urls.txt', 'w') as file:\n",
        "    for image_url in images:\n",
        "        file.write(image_url + \"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ooZOCTZ2PZCi",
        "outputId": "984bab49-2785-4947-ccde-f869719443ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRKY09SOJjsCOG_q6ilm-rbUJjcLaYfkDQZBzifN0k0s4cuqf_XoLOscNmTsco&s\n",
            "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTKSZdNfpeLu83S1DDcu1j3gQecGxdFff-8vhlzMng34-1n-CFgBd2mKbmrSg&s\n",
            "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRcDm03pS6ZaFGAhJv5cnV0lmo3iM89iHHWk0EyZK2VljdXp6Q3ApRwBnGCDcE&s\n",
            "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTaw7PMFcP1lxL3JibXZ4dHc729iigt1BhzWIrgBF0L65vrRVCZlHsYyv-cOQ&s\n",
            "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcR-TiABrxApDDXgpTjD729Y76MY8JWUj3eMMK8ZMhktKT4CvgEugi2S6tpJ84w&s\n",
            "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQ2RFc2luRg_a68Ek-mucM6-zscIQqnYzyU94GJi3gYQEpEDtxdpHzt8f1VlQ&s\n",
            "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTpgFPpBmilb_2wiKfdWumPyVuwBTe8kFdz-B-J6UyutTSnHwm14PvY51_QFA&s\n",
            "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTmcP_IKBJdS_FKwIWP_bRWhehv6wqS2dzR17DU4BTzUm-npHFZrw2oMcRFUkU&s\n",
            "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRYNzpkD_VIxtXkFvbYauZp09AIvwxYF2_LqTPJ38UGhURfCs6DDej7yiH--g&s\n",
            "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQIsHJtBhFXzHsLVy7ZWHJ2ZWgB4C-iPQym6wkdIcRdvb6eiENYfkWMju_7hQ&s\n",
            "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRJpr-PDZQxljkxIUBKNH8lB0e3_xsGve1KQ9YCe3JpGpVtg3Cb2HCct5QaZxQ&s\n",
            "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRzH4S5VYY_T2VQWMbl9R9PLtKQpB2NnfGfYI3yyCu9qezwf3l6TjTFwEqQ6A&s\n",
            "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcT5BMxGjnYouSIXSQhvPzONl1VFtF5q8d5sqrtj-QP62rxZclwMR14mxzU8OUo&s\n",
            "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRQDk4ABWwBQTDibBVvDh6st31EajFSTryjtCXCDGpmrv_5bpZIvu33rh3Xmg&s\n",
            "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTX_Q_d5MaedzF3ixy2lPAhEvBqh6qStWYu4RyDTqlxAgnfKZ1lAWwJ3IPikuk&s\n",
            "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRQyGjTdgOfTUFjW_niiTU1MNR9OaYJa5DP53oNpA453GWfJZWyQNdMNYsCmQ&s\n",
            "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQ4yABU1bNK7C7yImi4g5aTRTAgXcUpzW3IYVkYkb9J_Zooz1rQgxP89YjYstc&s\n",
            "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQauoRom3fGtgtUVNYiiJpf_H9e3xgJ7kXfNWmma9luhpmCPloU8Yxt5d2X&s\n",
            "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRsWd8LEoFgUu7R4B-JBKHY03U2udC38u-FYLKAc5z2WOjObzmlfEUntnFHv4E&s\n",
            "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSK-4yzm8yBgd6Ub-r-02Ku1wl-ebGfpu2hFVSYmQMRDhUoMVCkN0WdjGku3w&s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for i, image_url in enumerate(images):\n",
        "#     try:\n",
        "#         img_data = requests.get(image_url).content\n",
        "#         with open(f'image_{i}.jpg', 'wb') as handler:\n",
        "#             handler.write(img_data)\n",
        "#     except Exception as e:\n",
        "#         print(f\"Could not download {image_url}: {e}\")\n",
        "\n",
        "\n",
        "\n",
        "# define the folder where images will be stored\n",
        "folder_name = 'downloaded_images'\n",
        "\n",
        "# folder create agar already nhi h\n",
        "if not os.path.exists(folder_name):\n",
        "    os.makedirs(folder_name)\n",
        "\n",
        "# Loop through the list of image URLs\n",
        "for i, image_url in enumerate(images):\n",
        "    try:\n",
        "        # Request image data\n",
        "        img_data = requests.get(image_url).content\n",
        "\n",
        "        # Define the path for the image file including the folder name\n",
        "        file_path = os.path.join(folder_name, f'image_{i}.jpg')\n",
        "\n",
        "        # Open the file and write the image data\n",
        "        with open(file_path, 'wb') as handler:\n",
        "            handler.write(img_data)\n",
        "    except Exception as e:\n",
        "        print(f\"Could not download {image_url}: {e}\")\n"
      ],
      "metadata": {
        "id": "igV43pBCPa6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Directory where your images are stored\n",
        "IMAGE_DIR = 'folder_name'\n",
        "\n",
        "# Preprocessing transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Resize to the size expected by your model\n",
        "    transforms.ToTensor(),          # Convert to PyTorch Tensor\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalization\n",
        "])\n"
      ],
      "metadata": {
        "id": "PfurxieEZrYt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, img_dir, transform=None, transform_key=None):\n",
        "        self.img_dir = img_dir\n",
        "        self.img_names = os.listdir(img_dir)\n",
        "        self.transform = transform  # Transformation for the query image\n",
        "        self.transform_key = transform_key if transform_key else transform  # Transformation for the key image\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_names)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.img_names[idx])\n",
        "        image = Image.open(img_path).convert('RGB')  # Convert to RGB\n",
        "\n",
        "        im_q = self.transform(image) if self.transform else image  # Apply transformation to the query image\n",
        "        im_k = self.transform_key(image) if self.transform_key else image  # Apply transformation to the key image\n",
        "\n",
        "        return im_q, im_k\n"
      ],
      "metadata": {
        "id": "vIZ3mTkgafST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "# No need to import CustomImageDataset if it's defined in the same script\n",
        "\n",
        "# Define transformations for the query image\n",
        "transform_q = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    # ... add any other augmentations specific to your task ...\n",
        "])\n",
        "\n",
        "# Define transformations for the key image\n",
        "transform_k = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),  # Example of an additional transformation\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    # ... similar or different augmentations ...\n",
        "])\n",
        "\n",
        "# Assuming IMAGE_DIR is the path to your image directory\n",
        "# dataset = CustomImageDataset(IMAGE_DIR, transform=transform_q, transform_key=transform_k)\n",
        "# dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Now you can iterate over the dataloader in your training loop\n",
        "# for im_q, im_k in dataloader:\n",
        "#     # Process im_q and im_k through your MoCo model\n",
        "    # pass\n"
      ],
      "metadata": {
        "id": "XhCbqVx-wcFr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}